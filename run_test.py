#!/usr/bin/env python3
"""
è§†é¢‘ç›‘æ§æµ‹è¯•å·¥å…· - å•æ¨¡å‹æµ‹è¯• & å¤šæ¨¡å‹å¯¹æ¯”ï¼ˆå«æ€§èƒ½ç»Ÿè®¡ï¼‰
"""
import sys
import json
import time
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, field, asdict
from typing import List, Optional

import torch

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from config import VIDEO_DIR, OUTPUT_DIR, VLM_MODELS
from observation_layer import ObservationLayer
from utils.video_processor import VideoProcessor


# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class FrameResult:
    """å•å¸§ç»“æœ"""
    frame_id: int
    timestamp: float
    observation: str
    processing_time: float


@dataclass
class ModelResult:
    """å•ä¸ªæ¨¡å‹çš„æµ‹è¯•ç»“æœ"""
    model_key: str
    model_name: str
    load_time: float = 0.0
    vram_usage_gb: float = 0.0
    total_frames: int = 0
    total_time: float = 0.0
    avg_time_per_frame: float = 0.0
    min_time: float = 0.0
    max_time: float = 0.0
    frame_results: List[FrameResult] = field(default_factory=list)
    error: str = ""

    def to_dict(self):
        return {
            "model_key": self.model_key,
            "model_name": self.model_name,
            "load_time": round(self.load_time, 2),
            "vram_usage_gb": round(self.vram_usage_gb, 2),
            "total_frames": self.total_frames,
            "total_time": round(self.total_time, 2),
            "avg_time_per_frame": round(self.avg_time_per_frame, 2),
            "min_time": round(self.min_time, 2),
            "max_time": round(self.max_time, 2),
            "frame_results": [asdict(f) for f in self.frame_results],
            "error": self.error,
        }


@dataclass
class BenchmarkReport:
    """å®Œæ•´æµ‹è¯•æŠ¥å‘Š"""
    video_name: str
    video_duration: float
    sample_interval: float
    num_frames: int
    test_time: str
    gpu_name: str
    models: List[ModelResult] = field(default_factory=list)

    def to_dict(self):
        return {
            "video_name": self.video_name,
            "video_duration": round(self.video_duration, 2),
            "sample_interval": self.sample_interval,
            "num_frames": self.num_frames,
            "test_time": self.test_time,
            "gpu_name": self.gpu_name,
            "models": [m.to_dict() for m in self.models],
        }


# ==================== å·¥å…·å‡½æ•° ====================

def get_gpu_info() -> str:
    """è·å– GPU ä¿¡æ¯"""
    if torch.cuda.is_available():
        return torch.cuda.get_device_name(0)
    return "CPU"


def get_vram_usage() -> float:
    """è·å–å½“å‰æ˜¾å­˜ä½¿ç”¨é‡ (GB)"""
    if torch.cuda.is_available():
        return torch.cuda.memory_allocated() / 1024**3
    return 0.0


def list_test_videos():
    """åˆ—å‡ºæ‰€æœ‰æµ‹è¯•è§†é¢‘"""
    print(f"\næµ‹è¯•è§†é¢‘ç›®å½•: {VIDEO_DIR}")

    if not VIDEO_DIR.exists():
        print("ç›®å½•ä¸å­˜åœ¨!")
        return []

    videos = sorted(VIDEO_DIR.glob("*"))
    video_extensions = {'.mp4', '.avi', '.mkv', '.mov', '.webm'}
    valid_videos = [v for v in videos if v.suffix.lower() in video_extensions]

    print(f"æ‰¾åˆ° {len(valid_videos)} ä¸ªè§†é¢‘æ–‡ä»¶:\n")
    for i, v in enumerate(valid_videos, 1):
        print(f"  [{i}] {v.name}")

    return valid_videos


def select_video(videos):
    """é€‰æ‹©è¦æµ‹è¯•çš„è§†é¢‘"""
    while True:
        try:
            choice = input("\nè¯·é€‰æ‹©è§†é¢‘ç¼–å· (æˆ–è¾“å…¥ 'q' é€€å‡º): ").strip()
            if choice.lower() == 'q':
                return None
            idx = int(choice) - 1
            if 0 <= idx < len(videos):
                return videos[idx]
            print("æ— æ•ˆç¼–å·ï¼Œè¯·é‡è¯•")
        except ValueError:
            print("è¯·è¾“å…¥æ•°å­—")


def select_model():
    """é€‰æ‹©å•ä¸ªæ¨¡å‹"""
    models = list(VLM_MODELS.items())

    print("\nå¯ç”¨æ¨¡å‹:")
    for i, (key, info) in enumerate(models, 1):
        print(f"  [{i}] {key} - {info['description']}")

    while True:
        try:
            choice = input("\nè¯·é€‰æ‹©æ¨¡å‹ç¼–å·: ").strip()
            idx = int(choice) - 1
            if 0 <= idx < len(models):
                return models[idx][0]
            print("æ— æ•ˆç¼–å·ï¼Œè¯·é‡è¯•")
        except ValueError:
            print("è¯·è¾“å…¥æ•°å­—")


def select_models():
    """é€‰æ‹©å¤šä¸ªæ¨¡å‹"""
    models = list(VLM_MODELS.items())

    print("\nå¯ç”¨æ¨¡å‹ (è¾“å…¥ç¼–å·ï¼Œç©ºæ ¼åˆ†éš”ï¼Œæˆ– 'A' å…¨é€‰):")
    for i, (key, info) in enumerate(models, 1):
        print(f"  [{i}] {key} - {info['description']}")

    choice = input("\né€‰æ‹©: ").strip().upper()

    if choice == 'A':
        return [key for key, _ in models]

    selected = []
    for c in choice.split():
        try:
            idx = int(c) - 1
            if 0 <= idx < len(models):
                selected.append(models[idx][0])
        except ValueError:
            pass

    return selected if selected else [models[0][0]]


def select_interval():
    """é€‰æ‹©æŠ½å¸§é—´éš”"""
    print("\næŠ½å¸§é—´éš”é€‰é¡¹:")
    print("  [1] 1ç§’ (ç»†è‡´åˆ†æ)")
    print("  [2] 2ç§’ (æ¨è)")
    print("  [3] 5ç§’ (å¿«é€Ÿæµè§ˆ)")
    print("  [4] è‡ªå®šä¹‰")
    print("  [0] æ¯ä¸€å¸§ (æé™æµ‹è¯•ï¼Œéå¸¸è€—æ—¶!)")

    while True:
        try:
            choice = input("\nè¯·é€‰æ‹© (é»˜è®¤2): ").strip() or "2"
            if choice == "0":
                print("âš ï¸  è­¦å‘Šï¼šæ¯å¸§éƒ½å¤„ç†ä¼šéå¸¸è€—æ—¶ï¼")
                return 0.033  # çº¦30FPS
            elif choice == "1":
                return 1.0
            elif choice == "2":
                return 2.0
            elif choice == "3":
                return 5.0
            elif choice == "4":
                return float(input("è¾“å…¥é—´éš”ç§’æ•°: "))
            print("æ— æ•ˆé€‰æ‹©")
        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")


# ==================== æ‰“å°å‡½æ•° ====================

def print_comparison_table(report: BenchmarkReport):
    """æ‰“å°å¯¹æ¯”è¡¨æ ¼"""
    print("\n" + "=" * 95)
    print("  æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    print("=" * 95)
    print(f"  è§†é¢‘: {report.video_name} | å¸§æ•°: {report.num_frames} | GPU: {report.gpu_name}")
    print("=" * 95)

    # è¡¨å¤´
    print(f"\n{'æ¨¡å‹':<18} {'åŠ è½½æ—¶é—´':>10} {'æ˜¾å­˜':>10} {'å¹³å‡/å¸§':>10} {'æœ€å¿«':>10} {'æœ€æ…¢':>10} {'çŠ¶æ€':<10}")
    print("-" * 95)

    for m in report.models:
        if m.error:
            status = f"âŒ {m.error[:15]}"
            print(f"{m.model_key:<18} {'-':>10} {'-':>10} {'-':>10} {'-':>10} {'-':>10} {status}")
        else:
            status = "âœ…"
            print(f"{m.model_key:<18} {m.load_time:>8.2f}s {m.vram_usage_gb:>8.2f}GB "
                  f"{m.avg_time_per_frame:>8.2f}s {m.min_time:>8.2f}s {m.max_time:>8.2f}s {status}")

    print("-" * 95)

    # æ‰¾å‡ºæœ€å¿«çš„æ¨¡å‹
    successful = [m for m in report.models if not m.error]
    if successful:
        fastest = min(successful, key=lambda x: x.avg_time_per_frame)
        smallest_vram = min(successful, key=lambda x: x.vram_usage_gb)
        print(f"\nğŸ† æœ€å¿«: {fastest.model_key} ({fastest.avg_time_per_frame:.2f}s/å¸§)")
        print(f"ğŸ’¾ æœ€çœæ˜¾å­˜: {smallest_vram.model_key} ({smallest_vram.vram_usage_gb:.2f}GB)")


def print_observation_comparison(report: BenchmarkReport, frame_id: int = 0):
    """æ‰“å°æŒ‡å®šå¸§çš„è§‚å¯Ÿå¯¹æ¯”"""
    print(f"\n{'=' * 95}")
    print(f"  å¸§ {frame_id} è§‚å¯Ÿç»“æœå¯¹æ¯”")
    print("=" * 95)

    for m in report.models:
        if m.error:
            continue

        frame = next((f for f in m.frame_results if f.frame_id == frame_id), None)
        if frame:
            print(f"\nã€{m.model_key}ã€‘(è€—æ—¶: {frame.processing_time:.2f}s)")
            print("-" * 50)
            # é™åˆ¶æ˜¾ç¤ºé•¿åº¦
            obs = frame.observation
            if len(obs) > 500:
                obs = obs[:500] + "..."
            print(obs)


def save_report(report: BenchmarkReport) -> str:
    """ä¿å­˜æŠ¥å‘Šåˆ° JSON"""
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = OUTPUT_DIR / f"benchmark_{report.video_name}_{timestamp}.json"

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(report.to_dict(), f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
    return str(output_path)


# ==================== æµ‹è¯•å‡½æ•° ====================

def run_single_model_test():
    """å•æ¨¡å‹æµ‹è¯•"""
    videos = list_test_videos()
    if not videos:
        return

    video = select_video(videos)
    if not video:
        return

    model_key = select_model()
    interval = select_interval()

    max_frames_input = input("\næœ€å¤§å¤„ç†å¸§æ•° (ç›´æ¥å›è½¦å¤„ç†å…¨éƒ¨): ").strip()
    max_frames = int(max_frames_input) if max_frames_input else None

    print(f"\n{'='*60}")
    print(f"å¼€å§‹æµ‹è¯•")
    print(f"  è§†é¢‘: {video.name}")
    print(f"  æ¨¡å‹: {model_key}")
    print(f"  é—´éš”: {interval}ç§’")
    print(f"  æœ€å¤§å¸§æ•°: {max_frames or 'å…¨éƒ¨'}")
    print(f"{'='*60}")

    confirm = input("\nç¡®è®¤å¼€å§‹? (y/n): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆ")
        return

    with ObservationLayer(model_key=model_key) as layer:
        result = layer.process_video(
            video_path=str(video),
            sample_interval=interval,
            max_frames=max_frames,
        )
        layer.export_results(result.video_name)
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_DIR}")


def run_model_comparison():
    """å¤šæ¨¡å‹å¯¹æ¯”æµ‹è¯•ï¼ˆå¸¦æ€§èƒ½ç»Ÿè®¡ï¼‰"""
    videos = list_test_videos()
    if not videos:
        return

    video = select_video(videos)
    if not video:
        return

    selected_models = select_models()
    if len(selected_models) < 1:
        print("è¯·è‡³å°‘é€‰æ‹©1ä¸ªæ¨¡å‹")
        return

    interval = select_interval()

    max_frames_input = input("\næµ‹è¯•å¸§æ•° (ç›´æ¥å›è½¦=å¤„ç†å…¨éƒ¨ï¼Œè¾“å…¥æ•°å­—=é™åˆ¶å¸§æ•°): ").strip()
    max_frames = int(max_frames_input) if max_frames_input else None

    print(f"\n{'='*60}")
    print(f"å¼€å§‹å¤šæ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print(f"  è§†é¢‘: {video.name}")
    print(f"  æ¨¡å‹: {', '.join(selected_models)}")
    print(f"  é—´éš”: {interval}ç§’")
    print(f"  å¸§æ•°: {max_frames}")
    print(f"  GPU: {get_gpu_info()}")
    print(f"{'='*60}")

    confirm = input("\nç¡®è®¤å¼€å§‹? (y/n): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆ")
        return

    # è·å–è§†é¢‘ä¿¡æ¯
    processor = VideoProcessor(str(video))
    video_duration = processor.video_info.duration
    processor.close()

    # åˆå§‹åŒ–æŠ¥å‘Š
    report = BenchmarkReport(
        video_name=video.name,
        video_duration=video_duration,
        sample_interval=interval,
        num_frames=max_frames,
        test_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        gpu_name=get_gpu_info(),
    )

    # é€ä¸ªæµ‹è¯•æ¨¡å‹
    for model_idx, model_key in enumerate(selected_models):
        print(f"\n{'#' * 70}")
        print(f"# [{model_idx + 1}/{len(selected_models)}] æµ‹è¯•æ¨¡å‹: {model_key}")
        print(f"{'#' * 70}")

        model_info = VLM_MODELS.get(model_key, {})
        result = ModelResult(
            model_key=model_key,
            model_name=model_info.get("name", model_key),
        )

        try:
            # æ¸…ç†æ˜¾å­˜
            torch.cuda.empty_cache()
            if torch.cuda.is_available():
                torch.cuda.synchronize()

            # åˆ›å»ºè§‚å¯Ÿå±‚
            layer = ObservationLayer(model_key=None)

            # åŠ è½½æ¨¡å‹å¹¶è®¡æ—¶
            load_start = time.time()
            success = layer.load_model(model_key)
            result.load_time = time.time() - load_start

            if not success:
                result.error = "åŠ è½½å¤±è´¥"
                report.models.append(result)
                layer.close()
                continue

            result.vram_usage_gb = get_vram_usage()
            print(f"æ¨¡å‹åŠ è½½: {result.load_time:.2f}ç§’, æ˜¾å­˜: {result.vram_usage_gb:.2f}GB")

            # å¤„ç†è§†é¢‘
            processor = VideoProcessor(str(video))
            frame_times = []
            total_start = time.time()

            for frame_info in processor.extract_frames(interval=interval, max_frames=max_frames):
                frame_start = time.time()

                try:
                    observation = layer.vlm.generate(
                        images=frame_info.image,
                        prompt="è¯·ä»”ç»†è§‚å¯Ÿè¿™å¼ å›¾ç‰‡ï¼Œè¯¦ç»†æè¿°ï¼šåœºæ™¯ã€äººç‰©ã€åŠ¨ä½œã€ç‰©ä½“ã€‚ç”¨è‡ªç„¶æµç•…çš„ä¸­æ–‡ã€‚",
                        max_new_tokens=256,
                        temperature=0.7,
                    )
                except Exception as e:
                    observation = f"[é”™è¯¯: {e}]"

                frame_time = time.time() - frame_start
                frame_times.append(frame_time)

                result.frame_results.append(FrameResult(
                    frame_id=frame_info.frame_id,
                    timestamp=frame_info.timestamp,
                    observation=observation,
                    processing_time=frame_time,
                ))

                ts = f"{int(frame_info.timestamp // 60):02d}:{int(frame_info.timestamp % 60):02d}"
                print(f"  [å¸§ {frame_info.frame_id}] {ts} - {frame_time:.2f}s")

            processor.close()

            # ç»Ÿè®¡
            result.total_frames = len(frame_times)
            result.total_time = time.time() - total_start
            result.avg_time_per_frame = sum(frame_times) / len(frame_times) if frame_times else 0
            result.min_time = min(frame_times) if frame_times else 0
            result.max_time = max(frame_times) if frame_times else 0

            print(f"\n  ç»Ÿè®¡: å¹³å‡ {result.avg_time_per_frame:.2f}s/å¸§, "
                  f"æ€»è®¡ {result.total_time:.2f}s")

            layer.close()

        except Exception as e:
            result.error = str(e)
            print(f"æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

        report.models.append(result)
        torch.cuda.empty_cache()

    # æ‰“å°ç»“æœ
    print_comparison_table(report)
    print_observation_comparison(report, frame_id=0)

    # ä¿å­˜æŠ¥å‘Š
    save_report(report)


# ==================== å¤šå¸§æµ‹è¯• ====================

def run_multi_frame_test():
    """å¤šå¸§è¾“å…¥æµ‹è¯• - éªŒè¯åŠ¨æ€åŠ¨ä½œè¯†åˆ«"""
    videos = list_test_videos()
    if not videos:
        return

    video = select_video(videos)
    if not video:
        return

    model_key = select_model()

    print("\nå¤šå¸§æµ‹è¯•é…ç½®:")
    print("  å°†è¿ç»­Nå¸§ä¸€èµ·é€å…¥VLMï¼Œæµ‹è¯•èƒ½å¦è¯†åˆ«åŠ¨æ€åŠ¨ä½œ")

    # é…ç½®å‚æ•°
    num_frames = int(input("\nè¿ç»­å¸§æ•° (æ¨è3-5): ").strip() or "5")
    frame_interval = float(input("å¸§é—´éš”ç§’æ•° (æ¨è0.5-1): ").strip() or "0.5")
    start_time = float(input("èµ·å§‹æ—¶é—´ç§’ (é»˜è®¤0): ").strip() or "0")

    print(f"\n{'='*60}")
    print(f"å¤šå¸§åŠ¨æ€è¯†åˆ«æµ‹è¯•")
    print(f"  è§†é¢‘: {video.name}")
    print(f"  æ¨¡å‹: {model_key}")
    print(f"  å¸§æ•°: {num_frames} å¸§")
    print(f"  é—´éš”: {frame_interval} ç§’")
    print(f"  èŒƒå›´: {start_time}s ~ {start_time + num_frames * frame_interval}s")
    print(f"{'='*60}")

    confirm = input("\nç¡®è®¤å¼€å§‹? (y/n): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆ")
        return

    # æå–è¿ç»­å¸§
    processor = VideoProcessor(str(video))
    frames = []

    print(f"\næå– {num_frames} å¸§...")
    for i in range(num_frames):
        timestamp = start_time + i * frame_interval
        frame_info = processor.get_frame_at(timestamp)
        if frame_info:
            frames.append(frame_info.image)
            print(f"  å¸§ {i+1}: {timestamp:.1f}s âœ“")
        else:
            print(f"  å¸§ {i+1}: {timestamp:.1f}s âœ— (è¶…å‡ºè§†é¢‘èŒƒå›´)")

    processor.close()

    if len(frames) < 2:
        print("å¸§æ•°ä¸è¶³ï¼Œæ— æ³•æµ‹è¯•")
        return

    # åŠ è½½æ¨¡å‹
    print(f"\nåŠ è½½æ¨¡å‹ {model_key}...")
    from models.vlm_loader import VLMLoader
    vlm = VLMLoader()

    if not vlm.load_model(model_key):
        print("æ¨¡å‹åŠ è½½å¤±è´¥")
        return

    # å¤šå¸§ prompt
    multi_frame_prompt = """è¿™æ˜¯è¿ç»­çš„è§†é¢‘å¸§æˆªå›¾ï¼Œè¯·è§‚å¯Ÿè¿™äº›å›¾ç‰‡çš„å˜åŒ–ï¼Œå›ç­”ï¼š
1. åœºæ™¯æè¿°ï¼šè¿™æ˜¯ä»€ä¹ˆåœ°æ–¹ï¼Ÿ
2. äººç‰©åŠ¨ä½œï¼šäººç‰©æ­£åœ¨åšä»€ä¹ˆåŠ¨ä½œ/æ´»åŠ¨ï¼Ÿï¼ˆæ³¨æ„è§‚å¯Ÿå§¿åŠ¿å˜åŒ–ï¼‰
3. åŠ¨ä½œåˆ¤æ–­ï¼šè¿™æ˜¯é™æ­¢çš„è¿˜æ˜¯åŠ¨æ€çš„æ´»åŠ¨ï¼Ÿå¦‚æœæ˜¯åŠ¨æ€çš„ï¼Œå…·ä½“æ˜¯ä»€ä¹ˆæ´»åŠ¨ï¼ˆå¦‚è·³èˆã€èµ°è·¯ã€è¿åŠ¨ç­‰ï¼‰ï¼Ÿ
è¯·ç”¨ç®€æ´çš„ä¸­æ–‡å›ç­”ã€‚"""

    # å•å¸§å¯¹æ¯” prompt
    single_frame_prompt = "è¯·æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„åœºæ™¯ã€äººç‰©å’ŒåŠ¨ä½œã€‚"

    print(f"\n{'='*60}")
    print("æµ‹è¯•ç»“æœå¯¹æ¯”")
    print(f"{'='*60}")

    # æµ‹è¯•1: å•å¸§ï¼ˆç¬¬ä¸€å¸§ï¼‰
    print("\nã€å•å¸§æµ‹è¯•ã€‘ï¼ˆåªçœ‹ç¬¬ä¸€å¸§ï¼‰")
    print("-" * 50)
    start = time.time()
    single_result = vlm.generate(
        images=frames[0],
        prompt=single_frame_prompt,
        max_new_tokens=256,
        temperature=0.7,
    )
    single_time = time.time() - start
    print(f"è€—æ—¶: {single_time:.2f}s")
    print(single_result)

    # æµ‹è¯•2: å¤šå¸§
    print(f"\nã€å¤šå¸§æµ‹è¯•ã€‘ï¼ˆ{len(frames)}å¸§è¿ç»­ï¼‰")
    print("-" * 50)
    start = time.time()
    multi_result = vlm.generate(
        images=frames,
        prompt=multi_frame_prompt,
        max_new_tokens=512,
        temperature=0.7,
    )
    multi_time = time.time() - start
    print(f"è€—æ—¶: {multi_time:.2f}s")
    print(multi_result)

    # å¯¹æ¯”
    print(f"\n{'='*60}")
    print("æ€§èƒ½å¯¹æ¯”")
    print(f"{'='*60}")
    print(f"  å•å¸§: {single_time:.2f}s")
    print(f"  å¤šå¸§: {multi_time:.2f}s ({len(frames)}å¸§)")
    print(f"  å¤šå¸§/å•å¸§: {multi_time/single_time:.1f}x")

    vram = get_vram_usage()
    print(f"  æ˜¾å­˜å ç”¨: {vram:.2f}GB")

    vlm.unload_model()

    # ä¿å­˜ç»“æœ
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = OUTPUT_DIR / f"multiframe_test_{video.name}_{timestamp_str}.json"

    result = {
        "video": video.name,
        "model": model_key,
        "num_frames": len(frames),
        "frame_interval": frame_interval,
        "start_time": start_time,
        "single_frame": {
            "result": single_result,
            "time": single_time,
        },
        "multi_frame": {
            "result": multi_result,
            "time": multi_time,
        },
        "vram_gb": vram,
    }

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ ç»“æœå·²ä¿å­˜: {output_path}")


# ==================== ä¸»ç¨‹åº ====================

def main():
    """ä¸»èœå•"""
    print("\n" + "=" * 60)
    print("  è§†é¢‘ç›‘æ§è§‚å¯Ÿå±‚ - æµ‹è¯•å·¥å…·")
    print("=" * 60)

    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("  [1] å•æ¨¡å‹æµ‹è¯•")
        print("  [2] å¤šæ¨¡å‹å¯¹æ¯” (å«æ€§èƒ½ç»Ÿè®¡)")
        print("  [3] å¤šå¸§åŠ¨æ€è¯†åˆ«æµ‹è¯• â­")
        print("  [4] åˆ—å‡ºæµ‹è¯•è§†é¢‘")
        print("  [q] é€€å‡º")

        choice = input("\né€‰æ‹©: ").strip().lower()

        if choice == "1":
            run_single_model_test()
        elif choice == "2":
            run_model_comparison()
        elif choice == "3":
            run_multi_frame_test()
        elif choice == "4":
            list_test_videos()
        elif choice == "q":
            print("å†è§!")
            break
        else:
            print("æ— æ•ˆé€‰æ‹©")


if __name__ == "__main__":
    main()
